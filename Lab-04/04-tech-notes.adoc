= Lab 04 technical notes

This lab relies on the new templated Vagrant file. You need to:

* Clone Calavera
* Run ./template.sh, passing an argument 1-4 to it
* vagrant up the corresponding machines, now named cerebro1-4, brazos1-4, etc.

A 48 gb server can run 4 pipelines of 6 machines each.

== Previous notes

Crafting a Vagrant-based end to end DevOps pipeline that can support an entire class turned out to be a nontrivial undertaking, with some initially attempted approaches crashing and burning badly.

Vagrant has certain restrictions, and in particular restricts ssh access to VMs to the user under which they were created. If there are workarounds, I have not been able to find them - suggestions appreciated. So, this lab represents certain compromises.

The options considered were:

. each team has full control over own local pipeline (e.g. running on that person's laptop or course workstation)
. each team has full control over a distinct pipeline on the server (each team has own instance of 6 vms, for a total of e.g. 24 for a 4-team class, quite a load on the server)
.. the other issue with this was encountered Spring 2015 when machines from the various pipelines would disappear, probably due to Vagrant/Virtualbox networking issues
.. this is the preferred mode for Section II however and when the pipeline is switched to Docker we will revisit.
. one shared pipeline, with different apps having different URLs, but distinct dev instances run on their local laptops
. one shared pipeline, distinct dev instances on server
. one shared pipline, one dev server with separate apps
.. distinct Tomcat instances
.. distinct URLs

Option 2 was finally determined workable.

Considering final option:

In order to do this with Vagrant (and this is the major compromise) it is necessary for all students to access the Vagrant VMs as a single user, e.g. "public." Each student does `su public`, cds to /home/public/calavera, and then `ssh manos` (or whatever Calavera server they choose).

There is risk here; students would have the permissions to modify and destroy Calavera servers running under public, but we just have to manage this. Fortunately, any server can be easily rebuilt.

In order to do this, some brute force configuration is required including the creation of multiple dev directories and Tomcat URL mappings.

"Hijo" will remain the default primary product. For Lab 04 (as being implemented for 4 teams) we will add:

* gatito (kitten)
* perrito (puppy)
* potro (foal)
* cabrito (kid, i.e. baby goat)

This means that we need to handle 5 distinct

* development trees in /home
* build scripts
* Tomcat servlets
* githooks
* Jenkins jobs
* Artifactory packages
* Cara deployments

Here is the core idea for the lab: each team analyzes the reference model that Hijo provides, and replicates it. Worth a try...

trouble is, we wind up with a shared web.xml file for Tomcat. No good, for Section II, as each team is supposed to be independent. so, this resource will need to be restricted to overall Manos configuration and removed from the local team builds.

Each student, or subteam of 2 within the larger team, would have their own instance:

/home/gatito01 and /home/gatito02, both cloned from /home/gatito on Cerebro - this way they can do true collab dev.

In considering the complexity of retrofitting the entire pipeline with 5 sub-pipelines... this is too much work and complexity. Going to re-visit standing up 4 distinct pipelines on the server, trying different internet & username approaches.


== helpful links

* http://www.cyberciti.biz/cloud-computing/use-vagrant-to-create-small-virtual-lab-on-linux-osx/[How To Use Vagrant To Create Small Virtual Test Lab on a Linux / OS X / MS-Windows]
